{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "X2vec_Instacart_Gensim_FINAL_FOR_GITHUB.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boraturant/Word2Vec_Instacart_Similarity_Complementarity/blob/master/X2vec_Instacart_Gensim_FINAL_FOR_GITHUB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPhTVUUmLiAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install sklearn\n",
        "!pip install --upgrade gensim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKdh-gUlLkaP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import gensim\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.preprocessing.sequence import skipgrams\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "import io\n",
        "import urllib\n",
        "import collections\n",
        "import os\n",
        "import datetime\n",
        "import zipfile\n",
        "import urllib.request\n",
        "\n",
        "from sklearn.model_selection import train_test_split# Load the TensorBoard notebook extension\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9zTvdrv8Ypw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0L02JlxS8p0Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#DOWNLOAD CSVs\n",
        "#CSVs must be uploaded to your Google drive\n",
        "#3 million grocery orders from more than 200,000 Instacart users\n",
        "\n",
        "orders = pd.read_csv(\"/content/drive/My Drive/Instacart_Dataset/orders.csv\")\n",
        "prior_orders = pd.read_csv(\"/content/drive/My Drive/Instacart_Dataset/order_products__prior.csv\")\n",
        "train_orders = pd.read_csv(\"/content/drive/My Drive/Instacart_Dataset/order_products__train.csv\")\n",
        "products = pd.read_csv(\"/content/drive/My Drive/Instacart_Dataset/products.csv\").set_index('product_id')\n",
        "departments = pd.read_csv(\"/content/drive/My Drive/Instacart_Dataset/departments.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOuD9exk9nfc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CONVERT COLUMN TO STRING\n",
        "\n",
        "prior_orders[\"product_id\"] = prior_orders[\"product_id\"].astype(str) \n",
        "train_orders[\"product_id\"] = train_orders[\"product_id\"].astype(str)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6oaSJZh-0H6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#GET SENTENCES\n",
        "\n",
        "prior_products = prior_orders.groupby(\"order_id\").apply(lambda order: order['product_id'].tolist())\n",
        "train_products = train_orders.groupby(\"order_id\").apply(lambda order: order['product_id'].tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5IHC-bv-2Nr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#GET SENTENCES\n",
        "\n",
        "#sentences = prior_products.append(train_products)\n",
        "sentences=prior_products\n",
        "\n",
        "#NOTE: No need to keep all sentences in memory, could be loaded by iterators (https://rare-technologies.com/word2vec-tutorial/)\n",
        "\n",
        "longest = np.max(sentences.apply(len))\n",
        "#print(longest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5FhqsRq_GuI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CONVERT TO NUMPY ARRAY\n",
        "sentences = sentences.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RcgcW5SqP1O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#THE MODEL\n",
        "\n",
        "window_size=longest\n",
        "epochs=5\n",
        "embedding_size=100\n",
        "min_count=5  #Drop infrequent items in dataset\n",
        "number_of_negative_samples=7\n",
        "\n",
        "ns_exponent = 0\n",
        "\n",
        "sample=0 #Not included\n",
        "#(float, optional) â€“ The threshold for configuring which higher-frequency words are randomly downsampled, useful range is (0, 1e-5).\n",
        "\n",
        "#RUN THE MODEL\n",
        "model = gensim.models.Word2Vec(sentences, sg=1, size=embedding_size, window=window_size, min_count=min_count, workers=4, hs=0, negative=number_of_negative_samples,ns_exponent=ns_exponent, iter=epochs)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaHxz2YroKxj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SAVE MODEL\n",
        "\n",
        "model.save('/content/mymodel')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxxsiHGYB5KX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#LOAD MODEL\n",
        "#model = gensim.models.Word2Vec.load('/content/mymodel')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5lNsyqhc_o2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "wv\n",
        "This object essentially contains the mapping between words and embeddings. After training, it can be used directly to query those embeddings in various ways. \n",
        "See the module level docstring for examples.\n",
        "Type:\tWord2VecKeyedVectors\n",
        "\n",
        "vocabulary\n",
        "This object represents the vocabulary (sometimes called Dictionary in gensim) of the model. Besides keeping track of all unique words, \n",
        "this object provides extra functionality, such as constructing a huffman tree (frequent words are closer to the root), or discarding extremely rare words.\n",
        "Type:\tWord2VecVocab\n",
        "\n",
        "trainables\n",
        "This object represents the inner shallow neural network used to train the embeddings. The semantics of the network differ slightly in the \n",
        "two available training modes (CBOW or SG) but you can think of it as a NN with a single projection and hidden layer which we train on the corpus. \n",
        "The weights are then used as our embeddings (which means that the size of the hidden layer is equal to the number of features self.size).\n",
        "Type:\tWord2VecTrainables\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RErdsQDYzNj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The trained word vectors are stored in a KeyedVectors instance in model.wv:\n",
        "#vector = model.wv['computer']  # numpy vector of a word\n",
        "\n",
        "#You can perform various NLP word tasks with a trained model. Some of them are already built-in - you can see it in gensim.models.keyedvectors.\n",
        "\n",
        "#word_vectors = model.wv\n",
        "#del model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mQ9GN61nkBQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#NORMALIZE VECTORS\n",
        "\n",
        "#If you explicitly do an init_sims(replace=True) call,\n",
        "#you'll actually clobber the raw vectors, in-place, with the unit-normed vectors.\n",
        "\n",
        "#Precompute L2-normalized vectors.\n",
        "model.init_sims(replace=True) #Normalize Vectors\n",
        "\n",
        "#Deprecated. Use self.wv.init_sims instead. See init_sims()."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sk_8OKP05AMo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This is the target matrix (skip-gram negative sampling)\n",
        "#model.wv.vectors.shape \n",
        "#model.wv.vectors[1]\n",
        "\n",
        "#model.wv.vocab\n",
        "\n",
        "#model.wv.init_sims(replace=True)\n",
        "#model.wv.vectors_norm.shape  #(Normalized)\n",
        "#model.wv.vectors_norm[1]\n",
        "\n",
        "#This is the context matrix (skip-gram negative sampling)\n",
        "#model.trainables.syn1neg.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3W9eEoGJUD6F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CREATE EMBEDDING FILES FOR VISUALIZATION\n",
        "\n",
        "vocab_size=len(model.wv.vocab)\n",
        "\n",
        "my_dict = dict({})\n",
        "for idx, key in enumerate(model.wv.vocab):\n",
        "    #my_dict[key] = model.wv[key]\n",
        "    my_dict[key] = model.wv.get_vector(key)\n",
        "    #my_dict[key] = model.wv.word_vec(key, use_norm=True)\n",
        "\n",
        "#File Names\n",
        "target_vecs_fileLoc='target_vecs_GensimFinal.tsv'\n",
        "target_meta_fileLoc='target_meta_GensimFinal.tsv'\n",
        "\n",
        "\n",
        "#Delete if exists\n",
        "if os.path.exists(target_vecs_fileLoc):\n",
        "  os.remove(target_vecs_fileLoc)\n",
        "  \n",
        "if os.path.exists(target_meta_fileLoc):\n",
        "  os.remove(target_meta_fileLoc)\n",
        "  \n",
        "out_v = io.open(target_vecs_fileLoc, 'w', encoding='utf-8')\n",
        "out_m = io.open(target_meta_fileLoc, 'w', encoding='utf-8')\n",
        "\n",
        "#Meta File Header\n",
        "#out_m.write('ID\\tProductName\\tDepartment\\tEmbedding' + \"\\n\")\n",
        "out_m.write('ID\\tProductName\\tDepartment' + \"\\n\")\n",
        "\n",
        "for word_index in range(vocab_size):\n",
        "  \n",
        "  word =  list(model.wv.vocab.keys()) [word_index] \n",
        "    \n",
        "  #Embedding Vector\n",
        "  embeddings = model.wv.get_vector(word)\n",
        "  #embeddings = my_dict[word]\n",
        "\n",
        "  #META Input\n",
        "  productname = products.loc[int(word),'product_name']   \n",
        "  departmentName= str(products.loc[int(word),'department_id']) #str(departments[departments.department_id==int(products.loc[int(word),'department_id'])].department.apply(str)[0])\n",
        " \n",
        "  wordFinal= word + '\\t' + productname + '\\t'+departmentName #+ '\\t' + ','.join([str(x) for x in embeddings]) \n",
        "  \n",
        "  out_m.write(wordFinal + \"\\n\")\n",
        "  out_v.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n",
        "\n",
        "out_v.close()\n",
        "out_m.close()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOakmr-9AVCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://projector.tensorflow.org/\n",
        "# Save File and open in Embedding Projector\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "  pass\n",
        "else:\n",
        "  files.download(target_vecs_fileLoc)\n",
        "  files.download(target_meta_fileLoc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpxTpdEVil__",
        "colab_type": "text"
      },
      "source": [
        "# **Similarity**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HorUJuMZhZ30",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _l2_norm(m, replace=False):\n",
        "    \"\"\"Return an L2-normalized version of a matrix.\n",
        "    Parameters\n",
        "    ----------\n",
        "    m : np.array\n",
        "        The matrix to normalize.\n",
        "    replace : boolean, optional\n",
        "        If True, modifies the existing matrix.\n",
        "    Returns\n",
        "    -------\n",
        "    The normalized matrix.  If replace=True, this will be the same as m.\n",
        "    \"\"\"\n",
        "    dist = np.sqrt((m ** 2).sum(-1))[..., np.newaxis]\n",
        "    if replace:\n",
        "        m /= dist\n",
        "        return m\n",
        "    else:\n",
        "        return (m / dist).astype(np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncZ535QumzjR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Get_Similar_Items_With_Vector(target_Vector, number_of_items=10):\n",
        "\n",
        "  target_item_vector=_l2_norm(target_Vector,replace=False)\n",
        "  \n",
        "  vectors=[]\n",
        "  \n",
        "  #Source vectors must be in Normalized form\n",
        "  vectors=_l2_norm(model.wv.vectors,replace=False)\n",
        " \n",
        "  #DOT PRODUCT (COSINE SIMILARITY)  -1 0 1\n",
        "  dists = np.dot(vectors, target_item_vector)\n",
        "  \n",
        "  #sorted_dists= np.argsort(dists) #SORT - Sort distance indexes from smallest to largest!\n",
        "  #sorted_dists = gensim.matutils.argsort(dists, topn=number_of_items, reverse=False) # Same as the above line\n",
        "  \n",
        "  #IMPORTANT! sorted_dists must be from largest to smallest\n",
        "  sorted_dists = gensim.matutils.argsort(dists, topn=number_of_items+1, reverse=True) # Same as the above line\n",
        " \n",
        "  # Take the last n sorted distances\n",
        "  closest = sorted_dists[:number_of_items+1]\n",
        "  #return result[:topn]\n",
        "  #closest = closest[::-1]\n",
        "\n",
        "  #Don't return the searched item\n",
        "  result = [(model.wv.index2word[sim], float(dists[sim])) for sim in closest ]\n",
        "  return result[:number_of_items]\n",
        "    \n",
        "  #RETURN ITEM IDs\n",
        "  #result=[]\n",
        "  #for i in closest:\n",
        "  #  result.append(model.wv.index2word[i])\n",
        "\n",
        "  #return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud1C_Ktnzok7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Get_Similar_Items_IDs(target_Item, number_of_items=10):\n",
        "  \n",
        "  #target_item_vector = model.wv.word_vec(target_Item, use_norm=True) \n",
        "  target_item_vector= model.wv.get_vector(target_Item)\n",
        "  \n",
        "  target_item_vector=_l2_norm(target_item_vector,replace=False)\n",
        "  \n",
        "  vectors=[]\n",
        "  \n",
        "  #Source vectors must be in Normalized form\n",
        "  vectors=_l2_norm(model.wv.vectors,replace=False)\n",
        " \n",
        "  #DOT PRODUCT (COSINE SIMILARITY)  -1 0 1\n",
        "  dists = np.dot(vectors, target_item_vector)\n",
        "  \n",
        "  #sorted_dists= np.argsort(dists) #SORT - Sort distance indexes from smallest to largest!\n",
        "  #sorted_dists = gensim.matutils.argsort(dists, topn=number_of_items, reverse=False) # Same as the above line\n",
        "  \n",
        "  #IMPORTANT! sorted_dists must be from largest to smallest\n",
        "  sorted_dists = gensim.matutils.argsort(dists, topn=number_of_items+1, reverse=True) # Same as the above line\n",
        " \n",
        "  # Take the last n sorted distances\n",
        "  closest = sorted_dists[:number_of_items+1]\n",
        "  #return result[:topn]\n",
        "  #closest = closest[::-1]\n",
        "\n",
        "  #Don't return the searched item\n",
        "  result = [(model.wv.index2word[sim], float(dists[sim])) for sim in closest if sim not in [model.wv.vocab[target_Item].index]]\n",
        "  return result[:number_of_items]\n",
        "    \n",
        "  #RETURN ITEM IDs\n",
        "  #result=[]\n",
        "  #for i in closest:\n",
        "  #  result.append(model.wv.index2word[i])\n",
        "\n",
        "  #return result\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAz5YBOmoeAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Get_Complementary_Items_With_Vector(target_Vector, number_of_items=10, useNorm=False):\n",
        "  \n",
        "  if useNorm:\n",
        "      target_item_vector = _l2_norm(target_Vector,replace=False) \n",
        "  else:\n",
        "      target_item_vector = target_Vector\n",
        "  \n",
        "  #target_item_vector= model.wv.get_vector(target_Item)\n",
        "  \n",
        "  vectors=[]\n",
        "  \n",
        "  #Source vectors must not be normalized\n",
        "  if useNorm:\n",
        "      vectors= _l2_norm(model.trainables.syn1neg,replace=False)  \n",
        "  else:\n",
        "      vectors=model.trainables.syn1neg \n",
        "   \n",
        "  \n",
        "  #DOT PRODUCT (NOT COSINE SIMILARITY)  \n",
        "  dists = np.dot(vectors, target_item_vector)\n",
        "  \n",
        "  #sorted_dists= np.argsort(dists) #SORT - Sort distance indexes from smallest to largest!\n",
        "  #sorted_dists = gensim.matutils.argsort(dists, topn=number_of_items, reverse=False) # Same as the above line\n",
        "  \n",
        "  #IMPORTANT! sorted_dists must be from largest to smallest\n",
        "  sorted_dists = gensim.matutils.argsort(dists, topn=number_of_items+1, reverse=True) # Same as the above line\n",
        " \n",
        "  # Take the last n sorted distances\n",
        "  closest = sorted_dists[:number_of_items+1]\n",
        "  #return result[:topn]\n",
        "  #closest = closest[::-1]\n",
        "\n",
        "  #Don't return the searched item\n",
        "  result = [(model.wv.index2word[sim], float(dists[sim])) for sim in closest]\n",
        "  return result[:number_of_items]\n",
        "    \n",
        "  #RETURN ITEM IDs\n",
        "  #result=[]\n",
        "  #for i in closest:\n",
        "  #  result.append(model.wv.index2word[i])\n",
        "\n",
        "  #return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG14uDv0jIeh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Get_Complementary_Items_IDs(target_Item, number_of_items=10, useNorm=False):\n",
        "  \n",
        "  #Do not use norm vectors\n",
        "  #Similarity uses DotProduct, do not use norm vectors\n",
        "  \n",
        "  if useNorm:\n",
        "      target_item_vector = _l2_norm(model.wv.word_vec(target_Item, use_norm=False),replace=False) \n",
        "  else:\n",
        "      target_item_vector = model.wv.word_vec(target_Item, use_norm=False) \n",
        "  \n",
        "  \n",
        "  #target_item_vector= model.wv.get_vector(target_Item)\n",
        "  \n",
        "  vectors=[]\n",
        "  \n",
        "  #Source vectors must not be normalized\n",
        "  if useNorm:\n",
        "      vectors= _l2_norm(model.trainables.syn1neg,replace=False)  \n",
        "  else:\n",
        "      vectors=model.trainables.syn1neg\n",
        "   \n",
        "  \n",
        "  #DOT PRODUCT (NOT COSINE SIMILARITY)  \n",
        "  dists = np.dot(vectors, target_item_vector)\n",
        "  \n",
        "  #sorted_dists= np.argsort(dists) #SORT - Sort distance indexes from smallest to largest!\n",
        "  #sorted_dists = gensim.matutils.argsort(dists, topn=number_of_items, reverse=False) # Same as the above line\n",
        "  \n",
        "  #IMPORTANT! sorted_dists must be from largest to smallest\n",
        "  sorted_dists = gensim.matutils.argsort(dists, topn=number_of_items+1, reverse=True) # Same as the above line\n",
        " \n",
        "  # Take the last n sorted distances\n",
        "  closest = sorted_dists[:number_of_items+1]\n",
        "  #return result[:topn]\n",
        "  #closest = closest[::-1]\n",
        "\n",
        "  #Don't return the searched item\n",
        "  result = [(model.wv.index2word[sim], float(dists[sim])) for sim in closest if sim not in [model.wv.vocab[target_Item].index]]\n",
        "  return result[:number_of_items]\n",
        "    \n",
        "  #RETURN ITEM IDs\n",
        "  #result=[]\n",
        "  #for i in closest:\n",
        "  #  result.append(model.wv.index2word[i])\n",
        "\n",
        "  #return result\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_G-Seqpeh7Va",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Get_Similar_or_Complementary_Items_IDs(target_Item, similar, number_of_items=10):\n",
        "  \n",
        "  #Get Normalized Target Vector\n",
        "  #target_item_vector = model.wv.word_vec(target_Item, use_norm=True) \n",
        "  target_item_vector= model.wv.get_vector(target_Item)\n",
        "  \n",
        "  vectors=[]\n",
        "  \n",
        "  #Source vectors must be in Normalized form\n",
        "  if similar:\n",
        "    vectors=model.wv.vectors\n",
        "  else:\n",
        "    #Full Context Matrix\n",
        "    #model.trainables.syn1neg.shape\n",
        "    #fullContextVectors=model.wv.vectors #model.trainables.syn1neg\n",
        "    vectors=_l2_norm(model.trainables.syn1neg,False)\n",
        "    \n",
        "  #DOT PRODUCT (COSINE SIMILARITY)  -1 0 1\n",
        "  dists = np.dot(vectors, target_item_vector)\n",
        "  \n",
        "  #SORT - Sort distance indexes from smallest to largest!\n",
        "  sorted_dists= np.argsort(dists)\n",
        "  #sorted_dists = gensim.matutils.argsort(dists, topn=number_of_items, reverse=False) # Same as the above line\n",
        "  \n",
        "  #IMPORTANT! sorted_dists must be from largest to smallest\n",
        "  sorted_dists = gensim.matutils.argsort(dists, topn=number_of_items+1, reverse=True) # Same as the above line\n",
        " \n",
        "  # Take the last n sorted distances\n",
        "  closest = sorted_dists[:number_of_items+1]\n",
        "  #return result[:topn]\n",
        "  #closest = closest[::-1]\n",
        "\n",
        "  #Don't return the searched item\n",
        "  result = [(model.wv.index2word[sim], float(dists[sim])) for sim in closest if sim not in [model.wv.vocab[target_Item].index]]\n",
        "  return result[:number_of_items]\n",
        "    \n",
        "  #RETURN ITEM IDs\n",
        "  #result=[]\n",
        "  #for i in closest:\n",
        "  #  result.append(model.wv.index2word[i])\n",
        "\n",
        "  #return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NlQrceFwsYT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Get_Complementary_Items_IDs_WithGemsim(target_Item, embeddingDimension=100, number_of_items=10):\n",
        "\n",
        "  outv = gensim.models.KeyedVectors(embeddingDimension)\n",
        "  outv.vocab = model.wv.vocab  # same\n",
        "  outv.index2word = model.wv.index2word  # same\n",
        "  outv.syn0 = model.syn1neg  # different\n",
        "  #inout_similars = outv.most_similar('9065', topn=10)\n",
        "\n",
        "  inout_similars = outv.similar_by_vector(model.wv.get_vector(target_Item), topn=number_of_items) \n",
        "  #inout_similars = outv.most_similar(target_Item, topn=number_of_items) \n",
        "  \n",
        "  return inout_similars"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ji77Oudi7Ka4",
        "colab_type": "text"
      },
      "source": [
        "# **Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkfSDqYK7T-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load Model if trained before\n",
        "\n",
        "#model_File='/content/drive/My Drive/Models/mymodel_EP10_NEG20_NS00'\n",
        "#model = gensim.models.Word2Vec.load(model_File)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMjcEtf98XE9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test set\n",
        "train_orders = pd.read_csv(\"/content/drive/My Drive/Instacart_Dataset/order_products__train.csv\")\n",
        "train_orders[\"product_id\"] = train_orders[\"product_id\"].astype(str)  \n",
        "train_products = train_orders.groupby(\"order_id\").apply(lambda order: order['product_id'].tolist())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YE8_5h47CsrJ",
        "colab_type": "code",
        "outputId": "9a68f85d-4c5f-482c-abeb-73a88dbd50b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#In basket - Next product recommendation\n",
        "order_count=0\n",
        "evaluated_order_count=0\n",
        "\n",
        "evaluate_min_item_orders=2\n",
        "evaluate_n_missing_items=1\n",
        "hitCount=0\n",
        "\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "#Loop Orders\n",
        "for items in train_products.iteritems(): \n",
        "    order_count += 1\n",
        "    \n",
        "    #OrderID and Products\n",
        "    order_ID=items[0]\n",
        "    product_IDs=items[1]\n",
        "    \n",
        "    #Evaluate min basket size\n",
        "    if len(product_IDs)<=evaluate_min_item_orders:\n",
        "      continue\n",
        "    \n",
        "    #Pop n items from product_IDs\n",
        "    removed_ProductIDs=[]\n",
        "    for i in range(evaluate_n_missing_items):\n",
        "      removed_ProductIDs.append(product_IDs.pop())\n",
        "      \n",
        "      \n",
        "    #Get Vectors for Product IDs\n",
        "    try:\n",
        "      product_ID_Vectors=[_l2_norm(model.wv.get_vector(product_ID),replace=False) for product_ID in product_IDs]\n",
        "    except:\n",
        "      continue\n",
        "      \n",
        "    evaluated_order_count += 1\n",
        "    \n",
        "    product_ID_Vectors=np.asarray(product_ID_Vectors)\n",
        "    \n",
        "    #Get averaged Product_ID_Vectors\n",
        "    averaged_vector_for_products= np.mean(product_ID_Vectors,0)\n",
        "    #averaged_vector_for_products=tf.reduce_mean(product_ID_Vectors,0)\n",
        "    #print(averaged_vector_for_products)\n",
        "    \n",
        "    #Get Recommendations for the averaged_vector_for_products\n",
        "    recommendations=Get_Complementary_Items_With_Vector(averaged_vector_for_products,10,useNorm=True)\n",
        "    #recommendations=Get_Similar_Items_With_Vector(averaged_vector_for_products,10)\n",
        "    recommendations=[ recommendation[0] for recommendation in recommendations]\n",
        "    #print(recommendations)\n",
        "    \n",
        "    #print(type(product_IDs))\n",
        "    #print(len(product_IDs))\n",
        "    \n",
        "    \n",
        "    if (removed_ProductIDs[0] in recommendations) :\n",
        "      hitCount+=1\n",
        "    \n",
        "    #if evaluated_order_count==60000:\n",
        "    #  break\n",
        "\n",
        "print (hitCount/evaluated_order_count*100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8066596721762612\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FcTxRDD8ibT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}